# tools/pattern_analyzer_tool.py
"""
Tool 2: PatternAnalyzerTool
ì—­í• : LLM ê¸°ë°˜ ìš°ëŒ€ì¡°ê±´ íŒ¨í„´ ë¶„ì„ ë° RAG ì¿¼ë¦¬ ìƒì„±
"""

import json
from langchain.tools import BaseTool
from langchain.llms.base import LLM
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import PromptTemplate
from langchain.schema.runnable import RunnablePassthrough, RunnableLambda
from pydantic import BaseModel, Field
from typing import Optional

from prompts.question_filter_prompts import QuestionFilterPrompts
from schemas.question_filter_schema import ConditionExtractorResult, PatternAnalysisOutput, PatternAnalyzerResult



class PatternAnalyzerTool(BaseTool):
    """
    LLM ê¸°ë°˜ ìš°ëŒ€ì¡°ê±´ íŒ¨í„´ ë¶„ì„ ë° RAG ì¿¼ë¦¬ ìƒì„± Tool

    ì…ë ¥: ConditionExtractorResult
    ì¶œë ¥: PatternAnalyzerResult
    """

    name: str = "pattern_analyzer"
    description: str = "Analyzes rate information and preferential condition patterns using LLM and generates RAG queries for question generation."

    def __init__(self, llm: LLM, extracted_conditions: ConditionExtractorResult):
        """
        Tool ì´ˆê¸°í™”

        Args:
            llm: LangChain LLM ì¸ìŠ¤í„´ìŠ¤
            extracted_conditions: Tool 1ì˜ ì¶œë ¥ ê²°ê³¼
        """
        super().__init__()
        self.llm = llm
        self.extracted_conditions = extracted_conditions

        # Pydantic OutputParser ì„¤ì •
        self.output_parser = PydanticOutputParser(pydantic_object=PatternAnalysisOutput)

    def extract_analysis_data(self) -> dict[str, list[str]]:
        """
        ê¸ˆë¦¬ì •ë³´ì™€ ìš°ëŒ€ì¡°ê±´ í…ìŠ¤íŠ¸ ë¶„ë¦¬ ì¶”ì¶œ

        Returns:
            dict: ê¸ˆë¦¬ì •ë³´, ìš°ëŒ€ì¡°ê±´, ì€í–‰ëª…ì´ ë¶„ë¦¬ëœ ë”•ì…”ë„ˆë¦¬
        """
        rate_info_texts = []
        preferential_texts = []
        bank_names = set()

        for rate_chunk in self.extracted_conditions.rate_condition_chunks:
            bank_names.add(rate_chunk.product_name.split()[0])  # ì€í–‰ëª… ì¶”ì¶œ

            for chunk in rate_chunk.chunks:
                formatted_text = f"[{rate_chunk.product_name}] {chunk.content_natural}"

                if chunk.chunk_type == "basic_rate_info":
                    rate_info_texts.append(formatted_text)
                elif chunk.chunk_type == "preferential_details":
                    preferential_texts.append(formatted_text)

        return {
            "rate_info_texts": rate_info_texts,
            "preferential_texts": preferential_texts,
            "bank_names": list(bank_names)
        }

    @staticmethod
    def _convert_to_schema(llm_output: PatternAnalysisOutput) -> PatternAnalyzerResult:
        """
        LLM íŒŒì‹±ëœ ì¶œë ¥ì„ ìµœì¢… ê²°ê³¼ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜

        Args:
            llm_output: Pydantic OutputParserë¡œ íŒŒì‹±ëœ LLM ì¶œë ¥

        Returns:
            PatternAnalyzerResult: ìµœì¢… ê²°ê³¼ ìŠ¤í‚¤ë§ˆ
        """
        try:
            # RAG ì¿¼ë¦¬ ê¸°ë³¸ê°’ ì¶”ê°€ (ì‘ë‹µì´ ë¶€ì¡±í•œ ê²½ìš°)
            rag_queries = llm_output.rag_queries
            if not rag_queries:
                rag_queries = [
                    "ê¸ˆë¦¬ì •ë³´ ê¸°ë³¸ê¸ˆë¦¬ ìš°ëŒ€ê¸ˆë¦¬",
                    "ìš°ëŒ€ì¡°ê±´ ë§ˆì¼€íŒ… ìˆ˜ì‹  ë™ì˜",
                    "ìš°ëŒ€ì¡°ê±´ ëª¨ë°”ì¼ ì•± ì‚¬ìš©",
                    "ìš°ëŒ€ì¡°ê±´ ì¹´ë“œ ì‚¬ìš© ì‹¤ì ",
                    "íŒŒí‚¹í†µì¥ ê¸ˆë¦¬ ì¡°ê±´"
                ]

            result = PatternAnalyzerResult(
                analysis_patterns=llm_output.patterns,
                rag_queries=rag_queries,
                total_patterns=len(llm_output.patterns),
                analysis_success=True
            )

            return result

        except Exception as e:
            print(f"âŒ ìŠ¤í‚¤ë§ˆ ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
            return PatternAnalyzerResult(
                analysis_patterns=[],
                rag_queries=["ìš°ëŒ€ì¡°ê±´ íŒ¨í„´ ë¶„ì„", "ê¸ˆë¦¬ì •ë³´ íŒ¨í„´"],
                total_patterns=0,
                analysis_success=False
            )

    @staticmethod
    def _validate_input(extracted_conditions: ConditionExtractorResult) -> bool:
        """
        ì…ë ¥ ë°ì´í„° ê²€ì¦

        Args:
            extracted_conditions: Tool 1ì˜ ì¶œë ¥ ê²°ê³¼

        Returns:
            bool: ê²€ì¦ ì„±ê³µ ì—¬ë¶€
        """
        if not extracted_conditions.success:
            print("âŒ ConditionExtractorTool ì‹¤í–‰ì´ ì‹¤íŒ¨í•œ ìƒíƒœì…ë‹ˆë‹¤.")
            return False

        if not extracted_conditions.rate_condition_chunks:
            print("âŒ ë¶„ì„í•  ìš°ëŒ€ì¡°ê±´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        return True

    def _run(self) -> PatternAnalyzerResult:
        """
        Tool ì‹¤í–‰ ë©”ì¸ ë¡œì§

        Returns:
            PatternAnalyzerResult: íŒ¨í„´ ë¶„ì„ ê²°ê³¼
        """
        print("ğŸ”„ PatternAnalyzerTool ì‹¤í–‰ ì‹œì‘")

        # 1. ì…ë ¥ ë°ì´í„° ê²€ì¦
        if not self._validate_input(self.extracted_conditions):
            print("âŒ ì…ë ¥ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨")
            return PatternAnalyzerResult(
                analysis_patterns=[],
                rag_queries=[],
                total_patterns=0,
                analysis_success=False
            )

        try:
            # 2. ë¶„ì„ ë°ì´í„° ì¶”ì¶œ
            analysis_data = self.extract_analysis_data()
            print("ğŸ“ ë¶„ì„ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")

            # 3. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
            # í”„ë¡¬í”„íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° í…œí”Œë¦¿ êµ¬ì„±
            prompts = QuestionFilterPrompts()
            prompt_text = prompts.pattern_analysis(
                rate_info_texts=analysis_data["rate_info_texts"],
                preferential_texts=analysis_data["preferential_texts"],
                bank_names=analysis_data["bank_names"]
            )

            prompt_template = PromptTemplate(
                template=prompt_text + "\n\n{format_instructions}",
                input_variables=[],
                partial_variables={"format_instructions": self.output_parser.get_format_instructions()}
            )

            # 4. LCEL ì²´ì´ë‹ êµ¬ì„±
            chain = (
                    RunnablePassthrough()
                    | prompt_template
                    | self.llm
                    | self.output_parser
                    | RunnableLambda(self._convert_to_schema)
            )

            # 5. ì²´ì¸ ì‹¤í–‰
            result = chain.invoke({})
            print("ğŸ¤– LLM íŒ¨í„´ ë¶„ì„ ë° ë³€í™˜ ì™„ë£Œ")

            if result.analysis_success:
                print(
                    f"âœ… PatternAnalyzerTool ì‹¤í–‰ ì™„ë£Œ: {result.total_patterns}ê°œ íŒ¨í„´ ë¶„ì„, {len(result.rag_queries)}ê°œ RAG ì¿¼ë¦¬ ìƒì„±")
            else:
                print("âš ï¸ PatternAnalyzerTool ë¶€ë¶„ ì™„ë£Œ: ê¸°ë³¸ RAG ì¿¼ë¦¬ë¡œ ëŒ€ì²´")

            return result

        except Exception as e:
            print(f"âŒ PatternAnalyzerTool ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
            return PatternAnalyzerResult(
                analysis_patterns=[],
                rag_queries=["ìš°ëŒ€ì¡°ê±´ ì¼ë°˜ íŒ¨í„´", "ê¸ˆë¦¬ì •ë³´ ì¼ë°˜ íŒ¨í„´"],
                total_patterns=0,
                analysis_success=False
            )