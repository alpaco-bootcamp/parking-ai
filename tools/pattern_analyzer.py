"""
Tool 2: PatternAnalyzerTool
ì—­í• : LLM ê¸°ë°˜ ìš°ëŒ€ì¡°ê±´ íŒ¨í„´ ë¶„ì„ ë° RAG ì¿¼ë¦¬ ìƒì„±
"""

import json
from langchain.tools import BaseTool
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import PromptTemplate
from langchain.schema.runnable import RunnablePassthrough, RunnableLambda
from langchain_core.language_models import BaseLanguageModel

from prompts.question_prompts import QuestionPrompts
from schemas.question_tool_schema import (
    ConditionExtractorResult,
    PatternAnalysisOutput,
    PatternAnalyzerResult,
)
from langchain_core.runnables import Runnable


class PatternAnalyzerTool(Runnable):
    """
    LLM ê¸°ë°˜ ìš°ëŒ€ì¡°ê±´ íŒ¨í„´ ë¶„ì„ ë° RAG ì¿¼ë¦¬ ìƒì„± Tool

    ì¶œë ¥: PatternAnalyzerResult
    """

    def __init__(self, llm: BaseLanguageModel):
        """
        Tool ì´ˆê¸°í™”

        Args:
            llm: ì‚¬ìš©í•  llmëª¨ë¸
        """
        super().__init__()
        self.llm = llm

        # Pydantic OutputParser ì„¤ì •
        self.output_parser = PydanticOutputParser(pydantic_object=PatternAnalysisOutput)

    @staticmethod
    def _extract_analysis_data(
        extracted_conditions: ConditionExtractorResult,
    ) -> dict[str, list[str]]:
        """
        ê¸ˆë¦¬ì •ë³´ì™€ ìš°ëŒ€ì¡°ê±´ í…ìŠ¤íŠ¸ ë¶„ë¦¬ ì¶”ì¶œ

        Returns:
            dict: ê¸ˆë¦¬ì •ë³´, ìš°ëŒ€ì¡°ê±´, ì€í–‰ëª…ì´ ë¶„ë¦¬ëœ ë”•ì…”ë„ˆë¦¬
        """
        rate_info_texts = []
        preferential_texts = []
        bank_names = set()

        for product in extracted_conditions.products:
            bank_names.add(product.product_name.split()[0])  # ì€í–‰ëª… ì¶”ì¶œ

            for chunk in product.chunks:
                formatted_text = f"[{product.product_name}] {chunk.content_natural}"

                if chunk.chunk_type == "basic_rate_info":
                    rate_info_texts.append(formatted_text)
                elif chunk.chunk_type == "preferential_details":
                    preferential_texts.append(formatted_text)

        return {
            "rate_info_texts": rate_info_texts,
            "preferential_texts": preferential_texts,
            "bank_names": list(bank_names),
        }

    @staticmethod
    def _convert_to_schema(llm_output: PatternAnalysisOutput) -> PatternAnalyzerResult:
        """
        LLM íŒŒì‹±ëœ ì¶œë ¥ì„ ìµœì¢… ê²°ê³¼ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜

        Args:
            llm_output: Pydantic OutputParserë¡œ íŒŒì‹±ëœ LLM ì¶œë ¥

        Returns:
            PatternAnalyzerResult: ìµœì¢… ê²°ê³¼ ìŠ¤í‚¤ë§ˆ
        """
        try:
            # RAG ì¿¼ë¦¬ ê¸°ë³¸ê°’ ì¶”ê°€ (ì‘ë‹µì´ ë¶€ì¡±í•œ ê²½ìš°)
            rag_queries = llm_output.rag_queries
            if not rag_queries:
                rag_queries = [
                    "ê¸ˆë¦¬ì •ë³´ ê¸°ë³¸ê¸ˆë¦¬ ìš°ëŒ€ê¸ˆë¦¬",
                    "ìš°ëŒ€ì¡°ê±´ ë§ˆì¼€íŒ… ìˆ˜ì‹  ë™ì˜",
                    "ìš°ëŒ€ì¡°ê±´ ëª¨ë°”ì¼ ì•± ì‚¬ìš©",
                    "ìš°ëŒ€ì¡°ê±´ ì¹´ë“œ ì‚¬ìš© ì‹¤ì ",
                    "íŒŒí‚¹í†µì¥ ê¸ˆë¦¬ ì¡°ê±´",
                ]

            result = PatternAnalyzerResult(
                analysis_patterns=llm_output.patterns,
                rag_queries=rag_queries,
                total_patterns=len(llm_output.patterns),
                analysis_success=True,
            )

            return result

        except Exception as e:
            print(f"âŒ ìŠ¤í‚¤ë§ˆ ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
            return PatternAnalyzerResult(
                analysis_patterns=[],
                rag_queries=["ìš°ëŒ€ì¡°ê±´ íŒ¨í„´ ë¶„ì„", "ê¸ˆë¦¬ì •ë³´ íŒ¨í„´"],
                total_patterns=0,
                analysis_success=False,
            )

    @staticmethod
    def _validate_input(extracted_conditions: ConditionExtractorResult) -> bool:
        """
        ì…ë ¥ ë°ì´í„° ê²€ì¦

        Args:
            extracted_conditions: Tool 1ì˜ ì¶œë ¥ ê²°ê³¼

        Returns:
            bool: ê²€ì¦ ì„±ê³µ ì—¬ë¶€
        """
        if not extracted_conditions.success:
            print("âŒ ConditionExtractorTool ì‹¤í–‰ì´ ì‹¤íŒ¨í•œ ìƒíƒœì…ë‹ˆë‹¤.")
            return False

        if not extracted_conditions.products:
            print("âŒ ë¶„ì„í•  ìš°ëŒ€ì¡°ê±´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        return True

    def invoke(
        self, extracted_conditions: ConditionExtractorResult, config=None, **kwargs
    ) -> PatternAnalyzerResult:
        """
        Tool ì‹¤í–‰ ë©”ì¸ ë¡œì§

        Args:
            extracted_conditions: Tool 1ì˜ ì¶œë ¥ ê²°ê³¼
            config (dict, optional): LangChain ì‹¤í–‰ ì„¤ì •. Defaults to None.

        Returns:
            PatternAnalyzerResult: íŒ¨í„´ ë¶„ì„ ê²°ê³¼
        """
        print("ğŸ”„ PatternAnalyzerTool ì‹¤í–‰ ì‹œì‘")

        # 1. ì…ë ¥ ë°ì´í„° ê²€ì¦
        if not self._validate_input(extracted_conditions):
            print("âŒ ì…ë ¥ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨")
            return PatternAnalyzerResult(
                analysis_patterns=[],
                rag_queries=[],
                total_patterns=0,
                analysis_success=False,
            )

        try:
            # 2. ë¶„ì„ ë°ì´í„° ì¶”ì¶œ
            analysis_data = self._extract_analysis_data(extracted_conditions)
            print("ğŸ“ ë¶„ì„ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")

            # 3. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
            # í”„ë¡¬í”„íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° í…œí”Œë¦¿ êµ¬ì„±
            prompts = QuestionPrompts()
            prompt_text = prompts.pattern_analysis(
                rate_info_texts=analysis_data["rate_info_texts"],
                preferential_texts=analysis_data["preferential_texts"],
                bank_names=analysis_data["bank_names"],
            )

            prompt_template = PromptTemplate(
                template=prompt_text + "\n\n{format_instructions}",
                input_variables=[],
                partial_variables={
                    "format_instructions": self.output_parser.get_format_instructions()
                },
            )
            print(f"prompt_template: {prompt_template.template}")

            # 4. LCEL ì²´ì´ë‹ êµ¬ì„±
            chain = (
                RunnablePassthrough()
                | prompt_template
                | self.llm
                | self.output_parser
                | RunnableLambda(self._convert_to_schema)
            )

            print(f"ğŸ” llm ìš”ì²­ì¤‘..")

            # 5. ì²´ì¸ ì‹¤í–‰
            result = chain.invoke({})
            print("ğŸ¤– LLM íŒ¨í„´ ë¶„ì„ ë° ë³€í™˜ ì™„ë£Œ")

            if result.analysis_success:
                print(
                    f"âœ… PatternAnalyzerTool ì‹¤í–‰ ì™„ë£Œ: {result.total_patterns}ê°œ íŒ¨í„´ ë¶„ì„, {len(result.rag_queries)}ê°œ RAG ì¿¼ë¦¬ ìƒì„±"
                )
                for query in result.rag_queries:
                    print(f"âœ… query: {query}")

            else:
                print("âš ï¸ PatternAnalyzerTool ë¶€ë¶„ ì™„ë£Œ: ê¸°ë³¸ RAG ì¿¼ë¦¬ë¡œ ëŒ€ì²´")

            return result

        except Exception as e:
            print(f"âŒ PatternAnalyzerTool ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
            return PatternAnalyzerResult(
                analysis_patterns=[],
                rag_queries=["ìš°ëŒ€ì¡°ê±´ ì¼ë°˜ íŒ¨í„´", "ê¸ˆë¦¬ì •ë³´ ì¼ë°˜ íŒ¨í„´"],
                total_patterns=0,
                analysis_success=False,
            )
