import json
import pymongo
from typing import List, Dict, Any, Optional
from datetime import datetime

from pydantic import BaseModel, Field

from common.data import MONGO_URI, DB_NAME


# Pydantic ëª¨ë¸ ì •ì˜
class FullDocumentModel(BaseModel):
    """ì „ì²´ ë¬¸ì„œ í˜•íƒœì˜ ìì—°ì–´ ë³€í™˜ ë°ì´í„° ëª¨ë¸"""
    id: str = Field(..., alias="_id")  # ...: í•„ìˆ˜í•„ë“œ, MongoDB: _idë¡œ ì €ì¥/ì¡°íšŒ
    product_name: str
    full_content: str

    # _id, id í˜¸í™˜ ê°€ëŠ¥
    class Config:
        populate_by_name = True
        validate_by_name = True


class ChunkModel(BaseModel):
    """ì²­í¬ ë‹¨ìœ„ì˜ ìì—°ì–´ ë³€í™˜ ë°ì´í„° ëª¨ë¸"""
    # basic_info: ê¸°ë³¸ì •ë³´(ìƒí’ˆëª…, ì€í–‰, ê¸ˆë¦¬, ìœ í˜•, ê°€ì…ë°©ì‹)
    # product_guide: ê°€ì…ì •ë³´(ëŒ€ìƒ, ë°©ë²•, í•œë„)
    # rate_structure: ê¸ˆë¦¬êµ¬ê°„(ì˜ˆì¹˜ê¸ˆì•¡ë³„ ì°¨ë“±ê¸ˆë¦¬)
    # preferential_intro: ìš°ëŒ€ì¡°ê±´ ê°œìš”(introì •ë³´)
    # condition_N: ìš°ëŒ€ì¡°ê±´ ê°œë³„ë¶„ë¦¬

    product_code: str
    product_name: str
    chunk_type: str  # basic_info, product_guide, rate_structure, preferential_intro, condition_N
    chunk_index: int
    content: str


class ParkingProductNLPConverter:
    def __init__(self, mongo_uri: str, db_name: str):
        """
        MongoDB ì—°ê²° ì´ˆê¸°í™”
        """
        self.client = pymongo.MongoClient(mongo_uri)
        self.db = self.client[db_name]
        self.products_details = self.db['product_details']
        self.nlp_full = self.db['products_nlp_full']
        self.nlp_chunks = self.db['products_nlp_chunks']

    def convert_to_full_document(self, product: Dict[str, Any]) -> FullDocumentModel:
        """
        í†µì¥ ì •ë³´ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•íƒœì˜ ì „ì²´ ë¬¸ì„œë¡œ ë³€í™˜

        Args:
            product: products_details ì»¬ë ‰ì…˜ì˜ ë‹¨ì¼ ë¬¸ì„œ

        Returns:
            FullDocumentModel: ì „ì²´ ë¬¸ì„œ í˜•íƒœì˜ ìì—°ì–´ ë³€í™˜ ë°ì´í„°
        """
        product_name = product.get('product_name', 'ì•Œ ìˆ˜ ì—†ëŠ” ìƒí’ˆ')
        company_name = product.get('company_name', 'ì•Œ ìˆ˜ ì—†ëŠ” ì€í–‰')
        basic_rate = product.get('interest_rate', 0)
        prime_rate = product.get('prime_interest_rate', 0)
        rate_type = product.get('rate_type', 'ì¼ë°˜í˜•') # ë³€ë™ê¸ˆë¦¬..
        categories = product.get('categories', [])

        # ë§ˆí¬ë‹¤ìš´ í—¤ë”
        content = f"## {product_name}\n"
        content += f"### ì€í–‰: {company_name}\n"
        content += f"### ê¸°ë³¸ ê¸ˆë¦¬: {basic_rate}%\n"
        content += f"### ìµœê³  ìš°ëŒ€ê¸ˆë¦¬: {prime_rate}%\n"
        content += f"### ê¸ˆë¦¬ ìœ í˜•: {rate_type}\n"
        content += f"### ê°€ì… ë°©ì‹: {', '.join(categories) if categories else 'ì—†ìŒ'}\n"


        # ìƒí’ˆ ê°€ì´ë“œ ì •ë³´
        if 'product_guide' in product:
            guide = product['product_guide']
            if guide.get('target_customer'):
                content += f"### ê°€ì…ëŒ€ìƒ: {guide['target_customer']}\n"
            if guide.get('signup_method'):
                content += f"### ê°€ì…ë°©ë²•: {guide['signup_method']}\n"
            if guide.get('amount_limit'):
                content += f"### ê°€ì…í•œë„: {guide['amount_limit']}\n"

        interest_guide = product['interest_guide']

        # ê¸ˆë¦¬ êµ¬ê°„ ì •ë³´ (basic_rate_info)
        rate_info = interest_guide.get('basic_rate_info', [])
        if rate_info:
            content += "### ê¸ˆë¦¬ êµ¬ê°„:\n"
            for info in rate_info:
                # í˜•íƒœ 1: conditionê³¼ rateê°€ ìˆëŠ” ê²½ìš°
                if 'condition' in info and 'rate' in info:
                    content += f"  - {info['condition']}: {info['rate']}\n"
                # í˜•íƒœ 2: textë¡œ í†µí•©ëœ ê²½ìš°
                elif 'text' in info:
                    text_desc = info['text'].replace('\n', ' ').strip()
                    content += f"  - {text_desc}\n"

        # ìš°ëŒ€ì¡°ê±´ (preferential_detailsì—)
        # preferential_detailsì— conditionsê°€ ìˆëŠ”ì§€ í™•ì¸
        preferential_details = interest_guide.get('preferential_details', {})
        conditions = preferential_details.get('conditions', [])

        if conditions:
            content += "### ìš°ëŒ€ì¡°ê±´:\n"

            # introê°€ ìˆìœ¼ë©´ ë¨¼ì € ì¶”ê°€
            intro = preferential_details.get('intro', '')
            if intro:
                content += f"  - {intro}\n"

            # ê° ì¡°ê±´ë“¤ ì¶”ê°€ (index í™œìš©)
            for condition in conditions:
                condition_index = condition.get('index', '')
                desc = condition.get('description', '')
                if condition_index and desc:
                    content += f"  {condition_index}. {desc}\n"
                elif desc:  # indexê°€ ì—†ëŠ” ê²½ìš°
                    content += f"  - {desc}\n"
        else:
            content += "### ìš°ëŒ€ì¡°ê±´: ì—†ìŒ\n"


        content += "---\n"

        return FullDocumentModel(
            _id=product.get('_id', ''),
            product_name=product_name,
            full_content=content
        )

    def convert_to_chunks(self, product: Dict[str, Any]) -> List[ChunkModel]:
        """
        í†µì¥ ì •ë³´ë¥¼ ê¸°ëŠ¥ë³„ ì²­í¬ë¡œ ë¶„í• 

        Args:
            product: products_details ì»¬ë ‰ì…˜ì˜ ë‹¨ì¼ ë¬¸ì„œ

        Returns:
            List[ChunkModel]: ì²­í¬ ë‹¨ìœ„ì˜ ìì—°ì–´ ë³€í™˜ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        chunks = []
        product_id = product.get('_id', '')
        product_name = product.get('product_name', 'ì•Œ ìˆ˜ ì—†ëŠ” ìƒí’ˆ')
        company_name = product.get('company_name', 'ì•Œ ìˆ˜ ì—†ëŠ” ì€í–‰')

        # ì²­í¬ 1: ê¸°ë³¸ ì •ë³´
        basic_rate = product.get('interest_rate', 0)
        prime_rate = product.get('prime_interest_rate', 0)
        basic_content = f"{product_name}ì€ {company_name}ì˜ íŒŒí‚¹í†µì¥ìœ¼ë¡œ ê¸°ë³¸ê¸ˆë¦¬ {basic_rate}%, ìµœê³ ìš°ëŒ€ê¸ˆë¦¬ {prime_rate}%ë¥¼ ì œê³µí•©ë‹ˆë‹¤."

        chunks.append(ChunkModel(
            product_id=product_id,
            product_name=product_name,
            chunk_type='basic_info',
            chunk_index=1,
            content=basic_content
        ))

        chunk_index = 2

        # ì²­í¬ 2-N: ìš°ëŒ€ì¡°ê±´ë³„ ë¶„í• 
        if 'interest_guide' in product and 'preferential_details' in product['interest_guide']:
            conditions = product['interest_guide']['preferential_details'].get('conditions', [])
            for i, condition in enumerate(conditions):
                desc = condition.get('description', '').replace('\n', ' ').strip()
                # ê¸´ ì„¤ëª…ì€ í•µì‹¬ ë‚´ìš©ë§Œ ì¶”ì¶œ
                if len(desc) > 150:
                    desc = desc[:150] + "..."

                condition_content = f"{product_name}ì˜ ìš°ëŒ€ì¡°ê±´: {desc}"
                chunks.append(ChunkModel(
                    product_id=product_id,
                    product_name=product_name,
                    chunk_type=f'condition_{i + 1}',
                    chunk_index=chunk_index,
                    content=condition_content
                ))
                chunk_index += 1

        # ì²­í¬ N+1: ê°€ì… ì •ë³´
        if 'product_guide' in product:
            guide = product['product_guide']
            signup_parts = []

            if guide.get('target_customer'):
                signup_parts.append(f"ëŒ€ìƒ: {guide['target_customer']}")
            if guide.get('signup_method'):
                signup_parts.append(f"ë°©ë²•: {guide['signup_method']}")
            if guide.get('amount_limit'):
                signup_parts.append(f"í•œë„: {guide['amount_limit']}")

            if signup_parts:
                signup_content = f"{product_name} ê°€ì…ì •ë³´ - " + ", ".join(signup_parts)
                chunks.append(ChunkModel(
                    product_id=product_id,
                    product_name=product_name,
                    chunk_type='signup_info',
                    chunk_index=chunk_index,
                    content=signup_content
                ))

        return chunks

    def process_and_save(self):
        """
        products_detailsì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ ìì—°ì–´ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        """
        # ê¸°ì¡´ NLP ì»¬ë ‰ì…˜ ì´ˆê¸°í™”
        self.nlp_full.drop()
        self.nlp_chunks.drop()

        print("ğŸ“Š products_detailsì—ì„œ ë°ì´í„° ì½ëŠ” ì¤‘...")
        products = list(self.products_details.find())
        print(f"ì´ {len(products)}ê°œ ìƒí’ˆ ë°œê²¬")

        full_documents = []
        all_chunks = []

        for i, product in enumerate(products, 1):
            print(f"ì²˜ë¦¬ ì¤‘: {i}/{len(products)} - {product.get('product_name', 'Unknown')}")

            # Full Document ë³€í™˜
            full_doc_model = self.convert_to_full_document(product)
            # Pydantic ëª¨ë¸ì„ dictë¡œ ë³€í™˜í•˜ê³  created_at ì¶”ê°€
            full_doc_dict = full_doc_model.model_dump(by_alias=True)
            full_doc_dict['created_at'] = datetime.now()
            full_documents.append(full_doc_dict)

            # Chunks ë³€í™˜
            chunk_models = self.convert_to_chunks(product)
            for chunk_model in chunk_models:
                # Pydantic ëª¨ë¸ì„ dictë¡œ ë³€í™˜í•˜ê³  created_at ì¶”ê°€
                chunk_dict = chunk_model.model_dump()
                chunk_dict['created_at'] = datetime.now()
                all_chunks.append(chunk_dict)

        # MongoDBì— ì €ì¥
        print("\nğŸ’¾ Full Documents ì €ì¥ ì¤‘...")
        if full_documents:
            self.nlp_full.insert_many(full_documents)
            print(f"âœ… {len(full_documents)}ê°œ ì „ì²´ ë¬¸ì„œ ì €ì¥ ì™„ë£Œ")

        print("\nğŸ’¾ Chunks ì €ì¥ ì¤‘...")
        if all_chunks:
            self.nlp_chunks.insert_many(all_chunks)
            print(f"âœ… {len(all_chunks)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ")

        # í†µê³„ ì¶œë ¥
        self.print_statistics()

    def print_statistics(self):
        """
        ë³€í™˜ ê²°ê³¼ í†µê³„ ì¶œë ¥
        """
        print("\nğŸ“ˆ ë³€í™˜ ê²°ê³¼ í†µê³„")
        print("=" * 50)

        # Full Documents í†µê³„
        full_count = self.nlp_full.count_documents({})
        print(f"ì „ì²´ ë¬¸ì„œ ìˆ˜: {full_count}")

        if full_count > 0:
            # í‰ê·  ë¬¸ì„œ ê¸¸ì´
            pipeline = [
                {"$project": {"content_length": {"$strLenCP": "$full_content"}}},
                {"$group": {"_id": None, "avg_length": {"$avg": "$content_length"}}}
            ]
            result = list(self.nlp_full.aggregate(pipeline))
            if result:
                print(f"í‰ê·  ë¬¸ì„œ ê¸¸ì´: {result[0]['avg_length']:.0f} ê¸€ì")

        # Chunks í†µê³„
        chunk_count = self.nlp_chunks.count_documents({})
        print(f"ì´ ì²­í¬ ìˆ˜: {chunk_count}")

        if chunk_count > 0:
            # ì²­í¬ íƒ€ì…ë³„ ë¶„í¬
            pipeline = [
                {"$group": {"_id": "$chunk_type", "count": {"$sum": 1}}},
                {"$sort": {"count": -1}}
            ]
            chunk_stats = list(self.nlp_chunks.aggregate(pipeline))
            print("ì²­í¬ íƒ€ì…ë³„ ë¶„í¬:")
            for stat in chunk_stats:
                print(f"  - {stat['_id']}: {stat['count']}ê°œ")

        print("=" * 50)

    def sample_preview(self, limit: int = 3):
        """
        ë³€í™˜ ê²°ê³¼ ìƒ˜í”Œ ë¯¸ë¦¬ë³´ê¸°
        """
        print(f"\nğŸ” ë³€í™˜ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ {limit}ê°œ)")
        print("=" * 80)

        # Full Document ìƒ˜í”Œ
        print("ğŸ“„ Full Document ìƒ˜í”Œ:")
        for doc in self.nlp_full.find().limit(limit):
            print(f"\nìƒí’ˆëª…: {doc['product_name']}")
            print("ë‚´ìš©:")
            print(doc['full_content'])
            print("-" * 40)

        # Chunks ìƒ˜í”Œ
        print("\nğŸ§© Chunks ìƒ˜í”Œ:")
        for chunk in self.nlp_chunks.find().limit(limit):
            print(f"\nìƒí’ˆ: {chunk['product_name']} | íƒ€ì…: {chunk['chunk_type']}")
            print(f"ë‚´ìš©: {chunk['content']}")
            print("-" * 40)


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    try:
        converter = ParkingProductNLPConverter(MONGO_URI, DB_NAME)
        # print("ğŸš€ íŒŒí‚¹í†µì¥ ìì—°ì–´ ë³€í™˜ ì‹œì‘")
        # converter.process_and_save()
        #
        # print("\në¯¸ë¦¬ë³´ê¸°ë¥¼ í™•ì¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
        # choice = input().lower()
        # if choice == 'y':
        #     converter.sample_preview()

        # print("\nâœ… ë³€í™˜ ì™„ë£Œ!")

        # ë°ì´í„°ë§Œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ ì‚¬ìš© ì˜ˆì œ
        print("\nğŸ”§ ë°ì´í„° ë°˜í™˜ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸...")
        products = list(converter.products_details.find().limit(10))

        for product in products:
            # Full Documents ë³€í™˜ í…ŒìŠ¤íŠ¸
            full_doc = converter.convert_to_full_document(product)
            print(f"Full Document ë³€í™˜ ì™„ë£Œ: {full_doc.full_content}")
            print('===')
            # Chunks ë³€í™˜ í…ŒìŠ¤íŠ¸
            chunks = converter.convert_to_chunks(product)
            print(f"Chunks ë³€í™˜ ì™„ë£Œ: {chunks}")
            print('=' * 30)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()